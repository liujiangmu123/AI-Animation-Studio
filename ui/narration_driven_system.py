"""
AI Animation Studio - æ—ç™½é©±åŠ¨åˆ¶ä½œç³»ç»Ÿ
å®ç°ç²¾ç¡®åˆ°0.1ç§’çš„æ—¶é—´åŒæ­¥ç³»ç»Ÿï¼Œæ”¯æŒè‡ªåŠ¨æ—¶é—´æ®µè®¡ç®—å’Œå®Œç¾åŒæ­¥æœºåˆ¶
"""

from PyQt6.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
                             QSlider, QSpinBox, QDoubleSpinBox, QLineEdit, QTextEdit,
                             QListWidget, QListWidgetItem, QTreeWidget, QTreeWidgetItem,
                             QProgressBar, QFrame, QScrollArea, QGroupBox, QFormLayout,
                             QCheckBox, QComboBox, QMessageBox, QDialog, QTabWidget,
                             QSplitter, QApplication, QMenu, QToolButton)
from PyQt6.QtCore import Qt, pyqtSignal, QObject, QTimer, QThread, QPropertyAnimation, QEasingCurve, QRect
from PyQt6.QtGui import QFont, QColor, QIcon, QPixmap, QPainter, QBrush, QPen, QPalette
from PyQt6.QtMultimedia import QMediaPlayer, QAudioOutput

from enum import Enum
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
import json
import time
import math
import numpy as np
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import librosa
import soundfile as sf
from PyQt6.QtWidgets import QWidget, QVBoxLayout
from PyQt6.QtCore import pyqtSignal

from core.logger import get_logger
from core.data_structures import TimeSegment, AnimationType

logger = get_logger("narration_driven_system")


class NarrationDrivenSystem(QWidget):
    """æ—ç™½é©±åŠ¨ç³»ç»Ÿ - ä¸»è¦é›†æˆç±»"""

    def __init__(self, parent=None):
        super().__init__(parent)
        self.audio_analyzer = AudioAnalyzer()
        self.overlap_detector = TimeSegmentOverlapDetector()
        self.sync_validator = AudioAnimationSyncValidator()
        self.setup_ui()

    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        layout = QVBoxLayout(self)

        # åˆ›å»ºç²¾ç¡®æ—¶é—´è½´ç»„ä»¶
        self.timeline_widget = PreciseTimelineWidget()
        layout.addWidget(self.timeline_widget)

        # åˆ›å»ºæ³¢å½¢æ˜¾ç¤ºç»„ä»¶
        self.waveform_widget = PreciseWaveformWidget()
        layout.addWidget(self.waveform_widget)

        # åˆ›å»ºæ—¶é—´æ®µç»„ä»¶
        self.segments_widget = TimeSegmentsWidget()
        layout.addWidget(self.segments_widget)

        # è¿æ¥ä¿¡å·
        self.timeline_widget.time_changed.connect(self.waveform_widget.set_current_time)
        self.waveform_widget.time_clicked.connect(self.timeline_widget.set_current_time)

    def load_audio_file(self, file_path: str):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            # ä½¿ç”¨éŸ³é¢‘åˆ†æå™¨åˆ†ææ–‡ä»¶
            features = self.audio_analyzer.analyze_audio_file(file_path)

            # æ›´æ–°æ³¢å½¢æ˜¾ç¤º
            self.waveform_widget.load_audio_file(file_path)

            # æ›´æ–°æ—¶é—´è½´
            self.timeline_widget.set_audio_features(features)

            logger.info(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½æˆåŠŸ: {file_path}")

        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")

    def get_current_segments(self):
        """è·å–å½“å‰æ—¶é—´æ®µ"""
        return self.segments_widget.get_segments()

    def validate_sync(self):
        """éªŒè¯åŒæ­¥"""
        segments = self.get_current_segments()
        return self.sync_validator.validate_sync(segments)


class TimePrecision(Enum):
    """æ—¶é—´ç²¾åº¦æšä¸¾"""
    COARSE = 1.0        # ç²—ç³™ç²¾åº¦ - 1ç§’
    NORMAL = 0.5        # æ™®é€šç²¾åº¦ - 0.5ç§’
    FINE = 0.1          # ç²¾ç»†ç²¾åº¦ - 0.1ç§’
    ULTRA_FINE = 0.01   # è¶…ç²¾ç»†ç²¾åº¦ - 0.01ç§’


class SyncQuality(Enum):
    """åŒæ­¥è´¨é‡æšä¸¾"""
    BASIC = "basic"         # åŸºç¡€åŒæ­¥
    ENHANCED = "enhanced"   # å¢å¼ºåŒæ­¥
    PERFECT = "perfect"     # å®Œç¾åŒæ­¥


class AudioFeatureType(Enum):
    """éŸ³é¢‘ç‰¹å¾ç±»å‹æšä¸¾"""
    SILENCE = "silence"         # é™éŸ³æ®µ
    SPEECH = "speech"           # è¯­éŸ³æ®µ
    MUSIC = "music"             # éŸ³ä¹æ®µ
    NOISE = "noise"             # å™ªéŸ³æ®µ
    TRANSITION = "transition"   # è¿‡æ¸¡æ®µ


@dataclass
class AudioFeature:
    """éŸ³é¢‘ç‰¹å¾"""
    feature_type: AudioFeatureType
    start_time: float
    end_time: float
    confidence: float
    properties: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def duration(self) -> float:
        return self.end_time - self.start_time


@dataclass
class PreciseTimeSegment:
    """ç²¾ç¡®æ—¶é—´æ®µ"""
    segment_id: str
    start_time: float
    end_time: float
    description: str = ""
    narration_text: str = ""
    animation_type: AnimationType = AnimationType.MOVE
    elements: List[str] = field(default_factory=list)
    audio_features: List[AudioFeature] = field(default_factory=list)
    sync_quality: SyncQuality = SyncQuality.BASIC
    auto_generated: bool = False
    
    @property
    def duration(self) -> float:
        return self.end_time - self.start_time
    
    @property
    def precise_duration(self) -> float:
        """ç²¾ç¡®åˆ°0.1ç§’çš„æ—¶é•¿"""
        return round(self.duration, 1)


class AudioAnalyzer:
    """éŸ³é¢‘åˆ†æå™¨"""
    
    def __init__(self):
        self.sample_rate = 22050
        self.hop_length = 512
        self.frame_length = 2048
        
        logger.info("éŸ³é¢‘åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_audio_file(self, file_path: str) -> Tuple[np.ndarray, List[AudioFeature]]:
        """åˆ†æéŸ³é¢‘æ–‡ä»¶"""
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            y, sr = librosa.load(file_path, sr=self.sample_rate)
            
            # æå–éŸ³é¢‘ç‰¹å¾
            features = self.extract_audio_features(y, sr)
            
            logger.info(f"éŸ³é¢‘åˆ†æå®Œæˆ: {file_path}, ç‰¹å¾æ•°é‡: {len(features)}")
            return y, features
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}")
            return np.array([]), []
    
    def extract_audio_features(self, y: np.ndarray, sr: int) -> List[AudioFeature]:
        """æå–éŸ³é¢‘ç‰¹å¾"""
        features = []
        
        try:
            # æ£€æµ‹é™éŸ³æ®µ
            silence_features = self.detect_silence(y, sr)
            features.extend(silence_features)
            
            # æ£€æµ‹è¯­éŸ³æ®µ
            speech_features = self.detect_speech(y, sr)
            features.extend(speech_features)
            
            # æ£€æµ‹è¿‡æ¸¡æ®µ
            transition_features = self.detect_transitions(y, sr)
            features.extend(transition_features)
            
            # æŒ‰æ—¶é—´æ’åº
            features.sort(key=lambda f: f.start_time)
            
            return features
            
        except Exception as e:
            logger.error(f"æå–éŸ³é¢‘ç‰¹å¾å¤±è´¥: {e}")
            return []
    
    def detect_silence(self, y: np.ndarray, sr: int, threshold: float = 0.01) -> List[AudioFeature]:
        """æ£€æµ‹é™éŸ³æ®µ"""
        try:
            # è®¡ç®—RMSèƒ½é‡
            rms = librosa.feature.rms(y=y, hop_length=self.hop_length)[0]
            
            # æ£€æµ‹é™éŸ³
            silence_frames = rms < threshold
            
            # è½¬æ¢ä¸ºæ—¶é—´æ®µ
            silence_features = []
            in_silence = False
            start_time = 0.0
            
            for i, is_silent in enumerate(silence_frames):
                current_time = librosa.frames_to_time(i, sr=sr, hop_length=self.hop_length)
                
                if is_silent and not in_silence:
                    # é™éŸ³å¼€å§‹
                    start_time = current_time
                    in_silence = True
                elif not is_silent and in_silence:
                    # é™éŸ³ç»“æŸ
                    if current_time - start_time > 0.2:  # è‡³å°‘0.2ç§’çš„é™éŸ³
                        feature = AudioFeature(
                            feature_type=AudioFeatureType.SILENCE,
                            start_time=round(start_time, 1),
                            end_time=round(current_time, 1),
                            confidence=0.9,
                            properties={"threshold": threshold}
                        )
                        silence_features.append(feature)
                    in_silence = False
            
            return silence_features
            
        except Exception as e:
            logger.error(f"æ£€æµ‹é™éŸ³æ®µå¤±è´¥: {e}")
            return []
    
    def detect_speech(self, y: np.ndarray, sr: int) -> List[AudioFeature]:
        """æ£€æµ‹è¯­éŸ³æ®µ"""
        try:
            # ä½¿ç”¨è°±è´¨å¿ƒå’Œè¿‡é›¶ç‡æ£€æµ‹è¯­éŸ³
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=self.hop_length)[0]
            zero_crossings = librosa.feature.zero_crossing_rate(y, hop_length=self.hop_length)[0]
            
            # è¯­éŸ³ç‰¹å¾é˜ˆå€¼
            speech_frames = (spectral_centroids > 1000) & (zero_crossings > 0.1)
            
            # è½¬æ¢ä¸ºæ—¶é—´æ®µ
            speech_features = []
            in_speech = False
            start_time = 0.0
            
            for i, is_speech in enumerate(speech_frames):
                current_time = librosa.frames_to_time(i, sr=sr, hop_length=self.hop_length)
                
                if is_speech and not in_speech:
                    start_time = current_time
                    in_speech = True
                elif not is_speech and in_speech:
                    if current_time - start_time > 0.5:  # è‡³å°‘0.5ç§’çš„è¯­éŸ³
                        feature = AudioFeature(
                            feature_type=AudioFeatureType.SPEECH,
                            start_time=round(start_time, 1),
                            end_time=round(current_time, 1),
                            confidence=0.8,
                            properties={
                                "avg_centroid": float(np.mean(spectral_centroids[max(0, i-10):i])),
                                "avg_zcr": float(np.mean(zero_crossings[max(0, i-10):i]))
                            }
                        )
                        speech_features.append(feature)
                    in_speech = False
            
            return speech_features
            
        except Exception as e:
            logger.error(f"æ£€æµ‹è¯­éŸ³æ®µå¤±è´¥: {e}")
            return []
    
    def detect_transitions(self, y: np.ndarray, sr: int) -> List[AudioFeature]:
        """æ£€æµ‹è¿‡æ¸¡æ®µ"""
        try:
            # è®¡ç®—è°±å¯¹æ¯”åº¦å˜åŒ–
            spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=self.hop_length)
            contrast_diff = np.diff(spectral_contrast, axis=1)
            
            # æ£€æµ‹æ˜¾è‘—å˜åŒ–ç‚¹
            transition_threshold = np.std(contrast_diff) * 2
            transition_points = np.where(np.abs(contrast_diff).max(axis=0) > transition_threshold)[0]
            
            # è½¬æ¢ä¸ºè¿‡æ¸¡æ®µ
            transition_features = []
            for point in transition_points:
                time = librosa.frames_to_time(point, sr=sr, hop_length=self.hop_length)
                
                feature = AudioFeature(
                    feature_type=AudioFeatureType.TRANSITION,
                    start_time=round(max(0, time - 0.2), 1),
                    end_time=round(time + 0.2, 1),
                    confidence=0.7,
                    properties={"transition_strength": float(np.abs(contrast_diff).max(axis=0)[point])}
                )
                transition_features.append(feature)
            
            return transition_features
            
        except Exception as e:
            logger.error(f"æ£€æµ‹è¿‡æ¸¡æ®µå¤±è´¥: {e}")
            return []


class TimeSegmentOverlapDetector:
    """æ—¶é—´æ®µé‡å æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.tolerance = 0.1  # 0.1ç§’å®¹å·®
        
        logger.info("æ—¶é—´æ®µé‡å æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_overlaps(self, segments: List[PreciseTimeSegment]) -> List[Tuple[str, str, float]]:
        """æ£€æµ‹æ—¶é—´æ®µé‡å """
        overlaps = []
        
        try:
            # æŒ‰å¼€å§‹æ—¶é—´æ’åº
            sorted_segments = sorted(segments, key=lambda s: s.start_time)
            
            for i in range(len(sorted_segments)):
                for j in range(i + 1, len(sorted_segments)):
                    segment1 = sorted_segments[i]
                    segment2 = sorted_segments[j]
                    
                    # æ£€æŸ¥é‡å 
                    overlap_duration = self.calculate_overlap(segment1, segment2)
                    if overlap_duration > self.tolerance:
                        overlaps.append((segment1.segment_id, segment2.segment_id, overlap_duration))
            
            return overlaps
            
        except Exception as e:
            logger.error(f"æ£€æµ‹æ—¶é—´æ®µé‡å å¤±è´¥: {e}")
            return []
    
    def calculate_overlap(self, segment1: PreciseTimeSegment, segment2: PreciseTimeSegment) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ—¶é—´æ®µçš„é‡å æ—¶é•¿"""
        try:
            # è®¡ç®—é‡å åŒºé—´
            overlap_start = max(segment1.start_time, segment2.start_time)
            overlap_end = min(segment1.end_time, segment2.end_time)
            
            # å¦‚æœæœ‰é‡å ï¼Œè¿”å›é‡å æ—¶é•¿
            if overlap_start < overlap_end:
                return round(overlap_end - overlap_start, 1)
            else:
                return 0.0
                
        except Exception as e:
            logger.error(f"è®¡ç®—é‡å æ—¶é•¿å¤±è´¥: {e}")
            return 0.0
    
    def resolve_overlaps(self, segments: List[PreciseTimeSegment]) -> List[PreciseTimeSegment]:
        """è§£å†³æ—¶é—´æ®µé‡å """
        try:
            overlaps = self.detect_overlaps(segments)
            if not overlaps:
                return segments
            
            # åˆ›å»ºå‰¯æœ¬è¿›è¡Œä¿®æ”¹
            resolved_segments = [s for s in segments]
            
            for segment1_id, segment2_id, overlap_duration in overlaps:
                # æ‰¾åˆ°é‡å çš„æ—¶é—´æ®µ
                segment1 = next((s for s in resolved_segments if s.segment_id == segment1_id), None)
                segment2 = next((s for s in resolved_segments if s.segment_id == segment2_id), None)
                
                if segment1 and segment2:
                    # è°ƒæ•´ç¬¬äºŒä¸ªæ—¶é—´æ®µçš„å¼€å§‹æ—¶é—´
                    segment2.start_time = segment1.end_time + 0.1
                    
                    logger.info(f"è§£å†³é‡å : {segment1_id} å’Œ {segment2_id}, è°ƒæ•´æ—¶é•¿: {overlap_duration}s")
            
            return resolved_segments
            
        except Exception as e:
            logger.error(f"è§£å†³æ—¶é—´æ®µé‡å å¤±è´¥: {e}")
            return segments


class AudioAnimationSyncValidator:
    """éŸ³é¢‘åŠ¨ç”»åŒæ­¥éªŒè¯å™¨"""
    
    def __init__(self):
        self.sync_tolerance = 0.05  # 0.05ç§’åŒæ­¥å®¹å·®
        
        logger.info("éŸ³é¢‘åŠ¨ç”»åŒæ­¥éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def validate_sync(self, segment: PreciseTimeSegment, audio_features: List[AudioFeature]) -> bool:
        """éªŒè¯æ—¶é—´æ®µä¸éŸ³é¢‘çš„åŒæ­¥æ€§"""
        try:
            # æ£€æŸ¥æ—¶é—´æ®µæ˜¯å¦ä¸éŸ³é¢‘ç‰¹å¾å¯¹é½
            for feature in audio_features:
                if self.is_time_aligned(segment.start_time, feature.start_time):
                    return True
                if self.is_time_aligned(segment.end_time, feature.end_time):
                    return True
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è¯­éŸ³æ®µå†…
            for feature in audio_features:
                if (feature.feature_type == AudioFeatureType.SPEECH and
                    feature.start_time <= segment.start_time <= feature.end_time):
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"éªŒè¯åŒæ­¥æ€§å¤±è´¥: {e}")
            return False
    
    def is_time_aligned(self, time1: float, time2: float) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªæ—¶é—´ç‚¹æ˜¯å¦å¯¹é½"""
        return abs(time1 - time2) <= self.sync_tolerance
    
    def calculate_sync_score(self, segments: List[PreciseTimeSegment], 
                           audio_features: List[AudioFeature]) -> float:
        """è®¡ç®—æ•´ä½“åŒæ­¥åˆ†æ•°"""
        try:
            if not segments:
                return 0.0
            
            sync_count = 0
            for segment in segments:
                if self.validate_sync(segment, audio_features):
                    sync_count += 1
            
            return sync_count / len(segments)
            
        except Exception as e:
            logger.error(f"è®¡ç®—åŒæ­¥åˆ†æ•°å¤±è´¥: {e}")
            return 0.0
    
    def suggest_sync_improvements(self, segments: List[PreciseTimeSegment], 
                                audio_features: List[AudioFeature]) -> List[Dict[str, Any]]:
        """å»ºè®®åŒæ­¥æ”¹è¿›"""
        suggestions = []
        
        try:
            for segment in segments:
                if not self.validate_sync(segment, audio_features):
                    # æ‰¾åˆ°æœ€è¿‘çš„éŸ³é¢‘ç‰¹å¾
                    nearest_feature = self.find_nearest_feature(segment, audio_features)
                    if nearest_feature:
                        suggestion = {
                            "segment_id": segment.segment_id,
                            "current_start": segment.start_time,
                            "suggested_start": nearest_feature.start_time,
                            "reason": f"ä¸{nearest_feature.feature_type.value}ç‰¹å¾å¯¹é½",
                            "confidence": nearest_feature.confidence
                        }
                        suggestions.append(suggestion)
            
            return suggestions
            
        except Exception as e:
            logger.error(f"ç”ŸæˆåŒæ­¥å»ºè®®å¤±è´¥: {e}")
            return []
    
    def find_nearest_feature(self, segment: PreciseTimeSegment, 
                           audio_features: List[AudioFeature]) -> Optional[AudioFeature]:
        """æ‰¾åˆ°æœ€è¿‘çš„éŸ³é¢‘ç‰¹å¾"""
        try:
            min_distance = float('inf')
            nearest_feature = None
            
            for feature in audio_features:
                # è®¡ç®—åˆ°ç‰¹å¾å¼€å§‹æ—¶é—´çš„è·ç¦»
                distance = abs(segment.start_time - feature.start_time)
                if distance < min_distance:
                    min_distance = distance
                    nearest_feature = feature
            
            return nearest_feature if min_distance <= 1.0 else None
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾æœ€è¿‘ç‰¹å¾å¤±è´¥: {e}")
            return None


class PreciseTimelineWidget(QWidget):
    """ç²¾ç¡®æ—¶é—´è½´ç»„ä»¶"""

    # ä¿¡å·å®šä¹‰
    time_changed = pyqtSignal(float)                    # æ—¶é—´æ”¹å˜ä¿¡å·
    segment_selected = pyqtSignal(str)                  # æ—¶é—´æ®µé€‰æ‹©ä¿¡å·
    segment_created = pyqtSignal(dict)                  # æ—¶é—´æ®µåˆ›å»ºä¿¡å·
    segment_modified = pyqtSignal(str, dict)            # æ—¶é—´æ®µä¿®æ”¹ä¿¡å·
    sync_quality_changed = pyqtSignal(float)            # åŒæ­¥è´¨é‡æ”¹å˜ä¿¡å·

    def __init__(self, parent=None):
        super().__init__(parent)
        self.audio_file_path = ""
        self.audio_data = np.array([])
        self.audio_features = []
        self.segments = []
        self.current_time = 0.0
        self.duration = 0.0
        self.time_precision = TimePrecision.FINE
        self.sync_quality = SyncQuality.ENHANCED

        # åˆ†æå™¨å’ŒéªŒè¯å™¨
        self.audio_analyzer = AudioAnalyzer()
        self.overlap_detector = TimeSegmentOverlapDetector()
        self.sync_validator = AudioAnimationSyncValidator()

        # UIçŠ¶æ€
        self.selected_segment_id = None
        self.is_playing = False
        self.zoom_level = 1.0

        self.setup_ui()
        self.setup_connections()

        logger.info("ç²¾ç¡®æ—¶é—´è½´ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        layout = QVBoxLayout(self)

        # å·¥å…·æ 
        self.create_toolbar(layout)

        # æ—¶é—´è½´ä¸»ä½“
        self.create_timeline_body(layout)

        # æ§åˆ¶é¢æ¿
        self.create_control_panel(layout)

    def create_toolbar(self, layout):
        """åˆ›å»ºå·¥å…·æ """
        toolbar_frame = QFrame()
        toolbar_frame.setFrameStyle(QFrame.Shape.StyledPanel)
        toolbar_layout = QHBoxLayout(toolbar_frame)

        # ç²¾åº¦æ§åˆ¶
        precision_label = QLabel("æ—¶é—´ç²¾åº¦:")
        self.precision_combo = QComboBox()
        self.precision_combo.addItems(["ç²—ç³™(1s)", "æ™®é€š(0.5s)", "ç²¾ç»†(0.1s)", "è¶…ç²¾ç»†(0.01s)"])
        self.precision_combo.setCurrentIndex(2)  # é»˜è®¤ç²¾ç»†ç²¾åº¦
        self.precision_combo.currentIndexChanged.connect(self.on_precision_changed)

        toolbar_layout.addWidget(precision_label)
        toolbar_layout.addWidget(self.precision_combo)

        # åŒæ­¥è´¨é‡
        sync_label = QLabel("åŒæ­¥è´¨é‡:")
        self.sync_combo = QComboBox()
        self.sync_combo.addItems(["åŸºç¡€", "å¢å¼º", "å®Œç¾"])
        self.sync_combo.setCurrentIndex(1)  # é»˜è®¤å¢å¼ºåŒæ­¥
        self.sync_combo.currentIndexChanged.connect(self.on_sync_quality_changed)

        toolbar_layout.addWidget(sync_label)
        toolbar_layout.addWidget(self.sync_combo)

        toolbar_layout.addStretch()

        # è‡ªåŠ¨åˆ†ææŒ‰é’®
        self.analyze_btn = QPushButton("ğŸ” åˆ†æéŸ³é¢‘")
        self.analyze_btn.clicked.connect(self.analyze_audio)
        toolbar_layout.addWidget(self.analyze_btn)

        # è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æ®µæŒ‰é’®
        self.auto_generate_btn = QPushButton("âš¡ è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æ®µ")
        self.auto_generate_btn.clicked.connect(self.auto_generate_segments)
        toolbar_layout.addWidget(self.auto_generate_btn)

        # éªŒè¯åŒæ­¥æŒ‰é’®
        self.validate_btn = QPushButton("âœ… éªŒè¯åŒæ­¥")
        self.validate_btn.clicked.connect(self.validate_sync)
        toolbar_layout.addWidget(self.validate_btn)

        layout.addWidget(toolbar_frame)

    def create_timeline_body(self, layout):
        """åˆ›å»ºæ—¶é—´è½´ä¸»ä½“"""
        # ä½¿ç”¨åˆ†å‰²å™¨åˆ†ç¦»æ³¢å½¢å’Œæ—¶é—´æ®µ
        splitter = QSplitter(Qt.Orientation.Vertical)

        # æ³¢å½¢æ˜¾ç¤ºåŒºåŸŸ
        self.waveform_widget = PreciseWaveformWidget()
        self.waveform_widget.setMinimumHeight(120)
        self.waveform_widget.time_clicked.connect(self.on_time_clicked)
        splitter.addWidget(self.waveform_widget)

        # æ—¶é—´æ®µæ˜¾ç¤ºåŒºåŸŸ
        self.segments_widget = TimeSegmentsWidget()
        self.segments_widget.setMinimumHeight(100)
        self.segments_widget.segment_selected.connect(self.on_segment_selected)
        self.segments_widget.segment_modified.connect(self.on_segment_modified)
        splitter.addWidget(self.segments_widget)

        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹
        splitter.setSizes([120, 100])

        layout.addWidget(splitter)

    def create_control_panel(self, layout):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        control_frame = QFrame()
        control_frame.setFrameStyle(QFrame.Shape.StyledPanel)
        control_layout = QHBoxLayout(control_frame)

        # æ’­æ”¾æ§åˆ¶
        self.play_btn = QPushButton("â–¶ï¸")
        self.play_btn.setFixedSize(40, 30)
        self.play_btn.clicked.connect(self.toggle_playback)
        control_layout.addWidget(self.play_btn)

        self.stop_btn = QPushButton("â¹ï¸")
        self.stop_btn.setFixedSize(40, 30)
        self.stop_btn.clicked.connect(self.stop_playback)
        control_layout.addWidget(self.stop_btn)

        # æ—¶é—´æ˜¾ç¤º
        self.time_label = QLabel("00:00.0 / 00:00.0")
        self.time_label.setFont(QFont("Consolas", 10))
        control_layout.addWidget(self.time_label)

        control_layout.addStretch()

        # ç¼©æ”¾æ§åˆ¶
        zoom_label = QLabel("ç¼©æ”¾:")
        self.zoom_slider = QSlider(Qt.Orientation.Horizontal)
        self.zoom_slider.setRange(10, 500)
        self.zoom_slider.setValue(100)
        self.zoom_slider.setMaximumWidth(150)
        self.zoom_slider.valueChanged.connect(self.on_zoom_changed)

        control_layout.addWidget(zoom_label)
        control_layout.addWidget(self.zoom_slider)

        # åŒæ­¥åˆ†æ•°æ˜¾ç¤º
        self.sync_score_label = QLabel("åŒæ­¥åˆ†æ•°: --")
        control_layout.addWidget(self.sync_score_label)

        layout.addWidget(control_frame)

    def setup_connections(self):
        """è®¾ç½®ä¿¡å·è¿æ¥"""
        self.waveform_widget.time_changed.connect(self.on_time_changed)
        self.segments_widget.segment_created.connect(self.on_segment_created)

    def load_audio_file(self, file_path: str):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            self.audio_file_path = file_path

            # åˆ†æéŸ³é¢‘
            self.audio_data, self.audio_features = self.audio_analyzer.analyze_audio_file(file_path)

            if len(self.audio_data) > 0:
                # è®¡ç®—æ—¶é•¿
                self.duration = len(self.audio_data) / self.audio_analyzer.sample_rate

                # æ›´æ–°æ³¢å½¢æ˜¾ç¤º
                self.waveform_widget.set_audio_data(self.audio_data, self.audio_analyzer.sample_rate)
                self.waveform_widget.set_audio_features(self.audio_features)

                # æ›´æ–°æ—¶é—´æ®µæ˜¾ç¤º
                self.segments_widget.set_duration(self.duration)

                # å¯ç”¨æ§ä»¶
                self.analyze_btn.setEnabled(True)
                self.auto_generate_btn.setEnabled(True)
                self.validate_btn.setEnabled(True)

                # æ›´æ–°æ—¶é—´æ˜¾ç¤º
                self.update_time_display()

                logger.info(f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å®Œæˆ: {file_path}, æ—¶é•¿: {self.duration:.1f}s")

        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥:\n{str(e)}")

    def analyze_audio(self):
        """åˆ†æéŸ³é¢‘"""
        if not self.audio_file_path:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆåŠ è½½éŸ³é¢‘æ–‡ä»¶")
            return

        try:
            # é‡æ–°åˆ†æéŸ³é¢‘
            self.audio_data, self.audio_features = self.audio_analyzer.analyze_audio_file(self.audio_file_path)

            # æ›´æ–°æ˜¾ç¤º
            self.waveform_widget.set_audio_features(self.audio_features)

            # æ˜¾ç¤ºåˆ†æç»“æœ
            feature_count = len(self.audio_features)
            speech_count = sum(1 for f in self.audio_features if f.feature_type == AudioFeatureType.SPEECH)
            silence_count = sum(1 for f in self.audio_features if f.feature_type == AudioFeatureType.SILENCE)

            QMessageBox.information(
                self, "åˆ†æå®Œæˆ",
                f"éŸ³é¢‘åˆ†æå®Œæˆï¼\n\n"
                f"æ€»ç‰¹å¾æ•°: {feature_count}\n"
                f"è¯­éŸ³æ®µ: {speech_count}\n"
                f"é™éŸ³æ®µ: {silence_count}\n"
                f"è¿‡æ¸¡æ®µ: {feature_count - speech_count - silence_count}"
            )

        except Exception as e:
            logger.error(f"åˆ†æéŸ³é¢‘å¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"åˆ†æéŸ³é¢‘å¤±è´¥:\n{str(e)}")

    def auto_generate_segments(self):
        """è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æ®µ"""
        if not self.audio_features:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆåˆ†æéŸ³é¢‘")
            return

        try:
            # åŸºäºè¯­éŸ³æ®µç”Ÿæˆæ—¶é—´æ®µ
            generated_segments = []
            segment_id = 0

            for feature in self.audio_features:
                if feature.feature_type == AudioFeatureType.SPEECH and feature.duration >= 1.0:
                    segment = PreciseTimeSegment(
                        segment_id=f"auto_segment_{segment_id}",
                        start_time=feature.start_time,
                        end_time=feature.end_time,
                        description=f"è‡ªåŠ¨ç”Ÿæˆæ®µè½ {segment_id + 1}",
                        narration_text="",
                        animation_type=AnimationType.MOVE,
                        audio_features=[feature],
                        sync_quality=self.sync_quality,
                        auto_generated=True
                    )
                    generated_segments.append(segment)
                    segment_id += 1

            # æ£€æµ‹å’Œè§£å†³é‡å 
            resolved_segments = self.overlap_detector.resolve_overlaps(generated_segments)

            # æ·»åŠ åˆ°æ—¶é—´æ®µåˆ—è¡¨
            self.segments.extend(resolved_segments)

            # æ›´æ–°æ˜¾ç¤º
            self.segments_widget.set_segments(self.segments)

            # éªŒè¯åŒæ­¥
            self.validate_sync()

            QMessageBox.information(
                self, "ç”Ÿæˆå®Œæˆ",
                f"è‡ªåŠ¨ç”Ÿæˆäº† {len(resolved_segments)} ä¸ªæ—¶é—´æ®µ"
            )

        except Exception as e:
            logger.error(f"è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æ®µå¤±è´¥: {e}")
            QMessageBox.critical(self, "é”™è¯¯", f"è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æ®µå¤±è´¥:\n{str(e)}")

    def validate_sync(self):
        """éªŒè¯åŒæ­¥è´¨é‡"""
        if not self.segments or not self.audio_features:
            return

        try:
            # è®¡ç®—åŒæ­¥åˆ†æ•°
            sync_score = self.sync_validator.calculate_sync_score(self.segments, self.audio_features)

            # æ›´æ–°æ˜¾ç¤º
            self.sync_score_label.setText(f"åŒæ­¥åˆ†æ•°: {sync_score:.1%}")

            # å‘é€ä¿¡å·
            self.sync_quality_changed.emit(sync_score)

            # å¦‚æœåŒæ­¥è´¨é‡è¾ƒä½ï¼Œæä¾›æ”¹è¿›å»ºè®®
            if sync_score < 0.8:
                suggestions = self.sync_validator.suggest_sync_improvements(self.segments, self.audio_features)
                if suggestions:
                    self.show_sync_suggestions(suggestions)

        except Exception as e:
            logger.error(f"éªŒè¯åŒæ­¥è´¨é‡å¤±è´¥: {e}")

    def show_sync_suggestions(self, suggestions: List[Dict[str, Any]]):
        """æ˜¾ç¤ºåŒæ­¥å»ºè®®"""
        try:
            dialog = SyncSuggestionDialog(suggestions, self)
            if dialog.exec() == QDialog.DialogCode.Accepted:
                # åº”ç”¨å»ºè®®çš„ä¿®æ”¹
                applied_suggestions = dialog.get_applied_suggestions()
                for suggestion in applied_suggestions:
                    self.apply_sync_suggestion(suggestion)

                # é‡æ–°éªŒè¯
                self.validate_sync()

        except Exception as e:
            logger.error(f"æ˜¾ç¤ºåŒæ­¥å»ºè®®å¤±è´¥: {e}")

    def apply_sync_suggestion(self, suggestion: Dict[str, Any]):
        """åº”ç”¨åŒæ­¥å»ºè®®"""
        try:
            segment_id = suggestion["segment_id"]
            new_start_time = suggestion["suggested_start"]

            # æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´æ®µ
            for segment in self.segments:
                if segment.segment_id == segment_id:
                    # è°ƒæ•´æ—¶é—´
                    duration = segment.duration
                    segment.start_time = new_start_time
                    segment.end_time = new_start_time + duration

                    logger.info(f"åº”ç”¨åŒæ­¥å»ºè®®: {segment_id} -> {new_start_time:.1f}s")
                    break

            # æ›´æ–°æ˜¾ç¤º
            self.segments_widget.set_segments(self.segments)

        except Exception as e:
            logger.error(f"åº”ç”¨åŒæ­¥å»ºè®®å¤±è´¥: {e}")

    def on_precision_changed(self, index):
        """ç²¾åº¦æ”¹å˜äº‹ä»¶"""
        precisions = [TimePrecision.COARSE, TimePrecision.NORMAL, TimePrecision.FINE, TimePrecision.ULTRA_FINE]
        self.time_precision = precisions[index]

        # æ›´æ–°æ˜¾ç¤ºç²¾åº¦
        self.waveform_widget.set_time_precision(self.time_precision)
        self.segments_widget.set_time_precision(self.time_precision)

        logger.info(f"æ—¶é—´ç²¾åº¦è®¾ç½®ä¸º: {self.time_precision.value}s")

    def on_sync_quality_changed(self, index):
        """åŒæ­¥è´¨é‡æ”¹å˜äº‹ä»¶"""
        qualities = [SyncQuality.BASIC, SyncQuality.ENHANCED, SyncQuality.PERFECT]
        self.sync_quality = qualities[index]

        # æ›´æ–°éªŒè¯å™¨è®¾ç½®
        if self.sync_quality == SyncQuality.PERFECT:
            self.sync_validator.sync_tolerance = 0.01
        elif self.sync_quality == SyncQuality.ENHANCED:
            self.sync_validator.sync_tolerance = 0.05
        else:
            self.sync_validator.sync_tolerance = 0.1

        logger.info(f"åŒæ­¥è´¨é‡è®¾ç½®ä¸º: {self.sync_quality.value}")

    def on_time_clicked(self, time: float):
        """æ—¶é—´ç‚¹å‡»äº‹ä»¶"""
        self.set_current_time(time)

    def on_time_changed(self, time: float):
        """æ—¶é—´æ”¹å˜äº‹ä»¶"""
        self.set_current_time(time)

    def set_current_time(self, time: float):
        """è®¾ç½®å½“å‰æ—¶é—´"""
        # æ ¹æ®ç²¾åº¦è°ƒæ•´æ—¶é—´
        precision_value = self.time_precision.value
        self.current_time = round(time / precision_value) * precision_value

        # æ›´æ–°æ˜¾ç¤º
        self.update_time_display()
        self.waveform_widget.set_current_time(self.current_time)
        self.segments_widget.set_current_time(self.current_time)

        # å‘é€ä¿¡å·
        self.time_changed.emit(self.current_time)

    def update_time_display(self):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤º"""
        current_min = int(self.current_time // 60)
        current_sec = self.current_time % 60
        total_min = int(self.duration // 60)
        total_sec = self.duration % 60

        # æ ¹æ®ç²¾åº¦æ˜¾ç¤ºå°æ•°ä½
        if self.time_precision == TimePrecision.ULTRA_FINE:
            time_format = f"{current_min:02d}:{current_sec:05.2f} / {total_min:02d}:{total_sec:05.2f}"
        elif self.time_precision == TimePrecision.FINE:
            time_format = f"{current_min:02d}:{current_sec:04.1f} / {total_min:02d}:{total_sec:04.1f}"
        else:
            time_format = f"{current_min:02d}:{current_sec:02.0f} / {total_min:02d}:{total_sec:02.0f}"

        self.time_label.setText(time_format)

    def toggle_playback(self):
        """åˆ‡æ¢æ’­æ”¾çŠ¶æ€"""
        if self.is_playing:
            self.pause_playback()
        else:
            self.start_playback()

    def start_playback(self):
        """å¼€å§‹æ’­æ”¾"""
        self.is_playing = True
        self.play_btn.setText("â¸ï¸")
        # TODO: å®ç°å®é™…çš„éŸ³é¢‘æ’­æ”¾

    def pause_playback(self):
        """æš‚åœæ’­æ”¾"""
        self.is_playing = False
        self.play_btn.setText("â–¶ï¸")
        # TODO: å®ç°å®é™…çš„éŸ³é¢‘æš‚åœ

    def stop_playback(self):
        """åœæ­¢æ’­æ”¾"""
        self.is_playing = False
        self.play_btn.setText("â–¶ï¸")
        self.set_current_time(0.0)
        # TODO: å®ç°å®é™…çš„éŸ³é¢‘åœæ­¢

    def on_zoom_changed(self, value):
        """ç¼©æ”¾æ”¹å˜äº‹ä»¶"""
        self.zoom_level = value / 100.0
        self.waveform_widget.set_zoom_level(self.zoom_level)
        self.segments_widget.set_zoom_level(self.zoom_level)

    def on_segment_selected(self, segment_id: str):
        """æ—¶é—´æ®µé€‰æ‹©äº‹ä»¶"""
        self.selected_segment_id = segment_id
        self.segment_selected.emit(segment_id)

    def on_segment_created(self, segment_data: dict):
        """æ—¶é—´æ®µåˆ›å»ºäº‹ä»¶"""
        self.segment_created.emit(segment_data)

    def on_segment_modified(self, segment_id: str, changes: dict):
        """æ—¶é—´æ®µä¿®æ”¹äº‹ä»¶"""
        self.segment_modified.emit(segment_id, changes)

    def get_segments(self) -> List[PreciseTimeSegment]:
        """è·å–æ—¶é—´æ®µåˆ—è¡¨"""
        return self.segments.copy()

    def add_segment(self, segment: PreciseTimeSegment):
        """æ·»åŠ æ—¶é—´æ®µ"""
        self.segments.append(segment)
        self.segments_widget.set_segments(self.segments)
        self.validate_sync()

    def remove_segment(self, segment_id: str):
        """ç§»é™¤æ—¶é—´æ®µ"""
        self.segments = [s for s in self.segments if s.segment_id != segment_id]
        self.segments_widget.set_segments(self.segments)
        self.validate_sync()


class PreciseWaveformWidget(QWidget):
    """ç²¾ç¡®æ³¢å½¢æ˜¾ç¤ºç»„ä»¶"""

    # ä¿¡å·å®šä¹‰
    time_clicked = pyqtSignal(float)        # æ—¶é—´ç‚¹å‡»ä¿¡å·
    time_changed = pyqtSignal(float)        # æ—¶é—´æ”¹å˜ä¿¡å·
    region_selected = pyqtSignal(float, float)  # åŒºåŸŸé€‰æ‹©ä¿¡å·

    def __init__(self, parent=None):
        super().__init__(parent)
        self.audio_data = np.array([])
        self.sample_rate = 22050
        self.audio_features = []
        self.current_time = 0.0
        self.duration = 0.0
        self.zoom_level = 1.0
        self.time_precision = TimePrecision.FINE

        # é€‰æ‹©çŠ¶æ€
        self.selection_start = None
        self.selection_end = None
        self.is_selecting = False

        self.setMinimumHeight(120)
        self.setMouseTracking(True)

        logger.info("ç²¾ç¡®æ³¢å½¢æ˜¾ç¤ºç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def set_audio_data(self, audio_data: np.ndarray, sample_rate: int):
        """è®¾ç½®éŸ³é¢‘æ•°æ®"""
        self.audio_data = audio_data
        self.sample_rate = sample_rate
        self.duration = len(audio_data) / sample_rate if len(audio_data) > 0 else 0.0
        self.update()

    def set_audio_features(self, features: List[AudioFeature]):
        """è®¾ç½®éŸ³é¢‘ç‰¹å¾"""
        self.audio_features = features
        self.update()

    def set_current_time(self, time: float):
        """è®¾ç½®å½“å‰æ—¶é—´"""
        self.current_time = time
        self.update()

    def set_zoom_level(self, zoom: float):
        """è®¾ç½®ç¼©æ”¾çº§åˆ«"""
        self.zoom_level = zoom
        self.update()

    def set_time_precision(self, precision: TimePrecision):
        """è®¾ç½®æ—¶é—´ç²¾åº¦"""
        self.time_precision = precision
        self.update()

    def paintEvent(self, event):
        """ç»˜åˆ¶äº‹ä»¶"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        rect = self.rect()
        width = rect.width()
        height = rect.height()

        # ç»˜åˆ¶èƒŒæ™¯
        painter.fillRect(rect, QColor("#1e1e1e"))

        if len(self.audio_data) == 0:
            painter.setPen(QColor("#666666"))
            painter.drawText(rect, Qt.AlignmentFlag.AlignCenter, "è¯·åŠ è½½éŸ³é¢‘æ–‡ä»¶")
            return

        # ç»˜åˆ¶æ³¢å½¢
        self.draw_waveform(painter, width, height)

        # ç»˜åˆ¶éŸ³é¢‘ç‰¹å¾
        self.draw_audio_features(painter, width, height)

        # ç»˜åˆ¶æ—¶é—´åˆ»åº¦
        self.draw_time_scale(painter, width, height)

        # ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨
        self.draw_current_time_indicator(painter, width, height)

        # ç»˜åˆ¶é€‰æ‹©åŒºåŸŸ
        if self.selection_start is not None and self.selection_end is not None:
            self.draw_selection(painter, width, height)

    def draw_waveform(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶æ³¢å½¢"""
        try:
            if len(self.audio_data) == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)
            end_time = min(self.duration, start_time + visible_duration)

            # è½¬æ¢ä¸ºæ ·æœ¬ç´¢å¼•
            start_sample = int(start_time * self.sample_rate)
            end_sample = int(end_time * self.sample_rate)

            if start_sample >= len(self.audio_data):
                return

            # è·å–æ˜¾ç¤ºçš„éŸ³é¢‘æ•°æ®
            display_data = self.audio_data[start_sample:end_sample]

            if len(display_data) == 0:
                return

            # ä¸‹é‡‡æ ·ä»¥é€‚åº”æ˜¾ç¤ºå®½åº¦
            samples_per_pixel = max(1, len(display_data) // width)
            downsampled_data = []

            for i in range(0, len(display_data), samples_per_pixel):
                chunk = display_data[i:i + samples_per_pixel]
                if len(chunk) > 0:
                    downsampled_data.append(np.max(np.abs(chunk)))

            # ç»˜åˆ¶æ³¢å½¢
            painter.setPen(QPen(QColor("#4caf50"), 1))

            for i, amplitude in enumerate(downsampled_data):
                if i >= width:
                    break

                x = i
                wave_height = int(amplitude * height * 0.4)  # æ³¢å½¢é«˜åº¦å 40%
                center_y = height // 2

                painter.drawLine(x, center_y - wave_height, x, center_y + wave_height)

        except Exception as e:
            logger.error(f"ç»˜åˆ¶æ³¢å½¢å¤±è´¥: {e}")

    def draw_audio_features(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶éŸ³é¢‘ç‰¹å¾"""
        try:
            if not self.audio_features or self.duration == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)
            end_time = min(self.duration, start_time + visible_duration)

            for feature in self.audio_features:
                # æ£€æŸ¥ç‰¹å¾æ˜¯å¦åœ¨å¯è§èŒƒå›´å†…
                if feature.end_time < start_time or feature.start_time > end_time:
                    continue

                # è®¡ç®—ç‰¹å¾åœ¨å±å¹•ä¸Šçš„ä½ç½®
                feature_start_x = int((feature.start_time - start_time) / visible_duration * width)
                feature_end_x = int((feature.end_time - start_time) / visible_duration * width)

                # æ ¹æ®ç‰¹å¾ç±»å‹é€‰æ‹©é¢œè‰²
                if feature.feature_type == AudioFeatureType.SPEECH:
                    color = QColor("#2196f3")  # è“è‰²
                elif feature.feature_type == AudioFeatureType.SILENCE:
                    color = QColor("#757575")  # ç°è‰²
                elif feature.feature_type == AudioFeatureType.TRANSITION:
                    color = QColor("#ff9800")  # æ©™è‰²
                else:
                    color = QColor("#9c27b0")  # ç´«è‰²

                # ç»˜åˆ¶ç‰¹å¾åŒºåŸŸ
                painter.fillRect(feature_start_x, height - 20,
                               feature_end_x - feature_start_x, 20,
                               QColor(color.red(), color.green(), color.blue(), 100))

                # ç»˜åˆ¶ç‰¹å¾è¾¹ç•Œ
                painter.setPen(QPen(color, 2))
                painter.drawLine(feature_start_x, height - 20, feature_start_x, height)
                painter.drawLine(feature_end_x, height - 20, feature_end_x, height)

        except Exception as e:
            logger.error(f"ç»˜åˆ¶éŸ³é¢‘ç‰¹å¾å¤±è´¥: {e}")

    def draw_time_scale(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶æ—¶é—´åˆ»åº¦"""
        try:
            if self.duration == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)

            # æ ¹æ®ç²¾åº¦å’Œç¼©æ”¾çº§åˆ«ç¡®å®šåˆ»åº¦é—´éš”
            if self.time_precision == TimePrecision.ULTRA_FINE:
                interval = 0.1 if visible_duration < 10 else 1.0
            elif self.time_precision == TimePrecision.FINE:
                interval = 0.5 if visible_duration < 30 else 5.0
            else:
                interval = 1.0 if visible_duration < 60 else 10.0

            # ç»˜åˆ¶åˆ»åº¦
            painter.setPen(QPen(QColor("#666666"), 1))
            painter.setFont(QFont("Consolas", 8))

            current_mark = math.ceil(start_time / interval) * interval
            while current_mark <= start_time + visible_duration:
                x = int((current_mark - start_time) / visible_duration * width)

                if 0 <= x <= width:
                    # ç»˜åˆ¶åˆ»åº¦çº¿
                    painter.drawLine(x, height - 30, x, height - 20)

                    # ç»˜åˆ¶æ—¶é—´æ ‡ç­¾
                    if self.time_precision == TimePrecision.ULTRA_FINE:
                        time_text = f"{current_mark:.2f}s"
                    elif self.time_precision == TimePrecision.FINE:
                        time_text = f"{current_mark:.1f}s"
                    else:
                        time_text = f"{current_mark:.0f}s"

                    painter.drawText(x + 2, height - 5, time_text)

                current_mark += interval

        except Exception as e:
            logger.error(f"ç»˜åˆ¶æ—¶é—´åˆ»åº¦å¤±è´¥: {e}")

    def draw_current_time_indicator(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨"""
        try:
            if self.duration == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)

            # è®¡ç®—å½“å‰æ—¶é—´åœ¨å±å¹•ä¸Šçš„ä½ç½®
            if start_time <= self.current_time <= start_time + visible_duration:
                x = int((self.current_time - start_time) / visible_duration * width)

                # ç»˜åˆ¶æ—¶é—´çº¿
                painter.setPen(QPen(QColor("#f44336"), 3))
                painter.drawLine(x, 0, x, height)

                # ç»˜åˆ¶æ—¶é—´æ ‡ç­¾
                painter.setPen(QPen(QColor("#ffffff"), 1))
                painter.fillRect(x - 30, 5, 60, 20, QColor("#f44336"))
                painter.drawText(x - 25, 20, f"{self.current_time:.1f}s")

        except Exception as e:
            logger.error(f"ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨å¤±è´¥: {e}")

    def draw_selection(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶é€‰æ‹©åŒºåŸŸ"""
        try:
            if self.duration == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)

            # è®¡ç®—é€‰æ‹©åŒºåŸŸåœ¨å±å¹•ä¸Šçš„ä½ç½®
            sel_start_x = int((self.selection_start - start_time) / visible_duration * width)
            sel_end_x = int((self.selection_end - start_time) / visible_duration * width)

            # ç»˜åˆ¶é€‰æ‹©åŒºåŸŸ
            painter.fillRect(sel_start_x, 0, sel_end_x - sel_start_x, height,
                           QColor(255, 255, 0, 50))  # åŠé€æ˜é»„è‰²

            # ç»˜åˆ¶é€‰æ‹©è¾¹ç•Œ
            painter.setPen(QPen(QColor("#ffeb3b"), 2))
            painter.drawLine(sel_start_x, 0, sel_start_x, height)
            painter.drawLine(sel_end_x, 0, sel_end_x, height)

        except Exception as e:
            logger.error(f"ç»˜åˆ¶é€‰æ‹©åŒºåŸŸå¤±è´¥: {e}")

    def mousePressEvent(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if event.button() == Qt.MouseButton.LeftButton:
            time = self.pixel_to_time(event.position().x())

            if event.modifiers() & Qt.KeyboardModifier.ShiftModifier:
                # Shift+ç‚¹å‡»å¼€å§‹é€‰æ‹©
                self.selection_start = time
                self.is_selecting = True
            else:
                # æ™®é€šç‚¹å‡»è®¾ç½®å½“å‰æ—¶é—´
                self.time_clicked.emit(time)

    def mouseMoveEvent(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if self.is_selecting:
            self.selection_end = self.pixel_to_time(event.position().x())
            self.update()

    def mouseReleaseEvent(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        if self.is_selecting and event.button() == Qt.MouseButton.LeftButton:
            self.is_selecting = False

            if self.selection_start is not None and self.selection_end is not None:
                # ç¡®ä¿å¼€å§‹æ—¶é—´å°äºç»“æŸæ—¶é—´
                start = min(self.selection_start, self.selection_end)
                end = max(self.selection_start, self.selection_end)

                if end - start > 0.1:  # æœ€å°é€‰æ‹©é•¿åº¦0.1ç§’
                    self.region_selected.emit(start, end)

    def pixel_to_time(self, x: float) -> float:
        """åƒç´ åæ ‡è½¬æ¢ä¸ºæ—¶é—´"""
        if self.duration == 0:
            return 0.0

        visible_duration = self.duration / self.zoom_level
        start_time = max(0, self.current_time - visible_duration / 2)

        time = start_time + (x / self.width()) * visible_duration

        # æ ¹æ®ç²¾åº¦è°ƒæ•´
        precision_value = self.time_precision.value
        return round(time / precision_value) * precision_value

    def wheelEvent(self, event):
        """é¼ æ ‡æ»šè½®äº‹ä»¶ï¼ˆç¼©æ”¾ï¼‰"""
        delta = event.angleDelta().y()
        zoom_factor = 1.1 if delta > 0 else 0.9

        new_zoom = self.zoom_level * zoom_factor
        new_zoom = max(0.1, min(10.0, new_zoom))  # é™åˆ¶ç¼©æ”¾èŒƒå›´

        if new_zoom != self.zoom_level:
            self.zoom_level = new_zoom
            self.update()


class TimeSegmentsWidget(QWidget):
    """æ—¶é—´æ®µæ˜¾ç¤ºç»„ä»¶"""

    # ä¿¡å·å®šä¹‰
    segment_selected = pyqtSignal(str)              # æ—¶é—´æ®µé€‰æ‹©ä¿¡å·
    segment_created = pyqtSignal(dict)              # æ—¶é—´æ®µåˆ›å»ºä¿¡å·
    segment_modified = pyqtSignal(str, dict)        # æ—¶é—´æ®µä¿®æ”¹ä¿¡å·
    segment_deleted = pyqtSignal(str)               # æ—¶é—´æ®µåˆ é™¤ä¿¡å·

    def __init__(self, parent=None):
        super().__init__(parent)
        self.segments = []
        self.duration = 0.0
        self.current_time = 0.0
        self.zoom_level = 1.0
        self.time_precision = TimePrecision.FINE
        self.selected_segment_id = None

        # æ‹–æ‹½çŠ¶æ€
        self.dragging_segment = None
        self.drag_start_pos = None
        self.drag_mode = None  # 'move', 'resize_start', 'resize_end'

        self.setMinimumHeight(100)
        self.setMouseTracking(True)

        logger.info("æ—¶é—´æ®µæ˜¾ç¤ºç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def set_segments(self, segments: List[PreciseTimeSegment]):
        """è®¾ç½®æ—¶é—´æ®µåˆ—è¡¨"""
        self.segments = segments
        self.update()

    def set_duration(self, duration: float):
        """è®¾ç½®æ€»æ—¶é•¿"""
        self.duration = duration
        self.update()

    def set_current_time(self, time: float):
        """è®¾ç½®å½“å‰æ—¶é—´"""
        self.current_time = time
        self.update()

    def set_zoom_level(self, zoom: float):
        """è®¾ç½®ç¼©æ”¾çº§åˆ«"""
        self.zoom_level = zoom
        self.update()

    def set_time_precision(self, precision: TimePrecision):
        """è®¾ç½®æ—¶é—´ç²¾åº¦"""
        self.time_precision = precision
        self.update()

    def paintEvent(self, event):
        """ç»˜åˆ¶äº‹ä»¶"""
        painter = QPainter(self)
        painter.setRenderHint(QPainter.RenderHint.Antialiasing)

        rect = self.rect()
        width = rect.width()
        height = rect.height()

        # ç»˜åˆ¶èƒŒæ™¯
        painter.fillRect(rect, QColor("#2e2e2e"))

        if self.duration == 0:
            painter.setPen(QColor("#666666"))
            painter.drawText(rect, Qt.AlignmentFlag.AlignCenter, "è¯·è®¾ç½®æ—¶é•¿")
            return

        # ç»˜åˆ¶æ—¶é—´æ®µ
        self.draw_segments(painter, width, height)

        # ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨
        self.draw_current_time_indicator(painter, width, height)

    def draw_segments(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶æ—¶é—´æ®µ"""
        try:
            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)
            end_time = min(self.duration, start_time + visible_duration)

            for segment in self.segments:
                # æ£€æŸ¥æ—¶é—´æ®µæ˜¯å¦åœ¨å¯è§èŒƒå›´å†…
                if segment.end_time < start_time or segment.start_time > end_time:
                    continue

                # è®¡ç®—æ—¶é—´æ®µåœ¨å±å¹•ä¸Šçš„ä½ç½®
                seg_start_x = int((segment.start_time - start_time) / visible_duration * width)
                seg_end_x = int((segment.end_time - start_time) / visible_duration * width)
                seg_width = seg_end_x - seg_start_x

                # æ ¹æ®æ—¶é—´æ®µç±»å‹é€‰æ‹©é¢œè‰²
                if segment.segment_id == self.selected_segment_id:
                    color = QColor("#ff5722")  # é€‰ä¸­é¢œè‰²
                elif segment.auto_generated:
                    color = QColor("#9c27b0")  # è‡ªåŠ¨ç”Ÿæˆé¢œè‰²
                else:
                    color = QColor("#2196f3")  # é»˜è®¤é¢œè‰²

                # ç»˜åˆ¶æ—¶é—´æ®µçŸ©å½¢
                painter.fillRect(seg_start_x, 10, seg_width, height - 20, color)

                # ç»˜åˆ¶è¾¹æ¡†
                painter.setPen(QPen(QColor("#ffffff"), 1))
                painter.drawRect(seg_start_x, 10, seg_width, height - 20)

                # ç»˜åˆ¶æ—¶é—´æ®µæ–‡æœ¬
                if seg_width > 50:  # åªæœ‰è¶³å¤Ÿå®½åº¦æ—¶æ‰æ˜¾ç¤ºæ–‡æœ¬
                    painter.setPen(QColor("#ffffff"))
                    painter.setFont(QFont("Microsoft YaHei", 8))

                    # æ—¶é—´æ®µæè¿°
                    text_rect = QRect(seg_start_x + 5, 15, seg_width - 10, 20)
                    painter.drawText(text_rect, Qt.AlignmentFlag.AlignLeft, segment.description)

                    # æ—¶é—´ä¿¡æ¯
                    time_text = f"{segment.start_time:.1f}s - {segment.end_time:.1f}s"
                    time_rect = QRect(seg_start_x + 5, height - 25, seg_width - 10, 15)
                    painter.drawText(time_rect, Qt.AlignmentFlag.AlignLeft, time_text)

                # ç»˜åˆ¶è°ƒæ•´æ‰‹æŸ„
                if segment.segment_id == self.selected_segment_id:
                    # å·¦ä¾§è°ƒæ•´æ‰‹æŸ„
                    painter.fillRect(seg_start_x - 3, 10, 6, height - 20, QColor("#ffffff"))
                    # å³ä¾§è°ƒæ•´æ‰‹æŸ„
                    painter.fillRect(seg_end_x - 3, 10, 6, height - 20, QColor("#ffffff"))

        except Exception as e:
            logger.error(f"ç»˜åˆ¶æ—¶é—´æ®µå¤±è´¥: {e}")

    def draw_current_time_indicator(self, painter: QPainter, width: int, height: int):
        """ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨"""
        try:
            if self.duration == 0:
                return

            # è®¡ç®—æ˜¾ç¤ºèŒƒå›´
            visible_duration = self.duration / self.zoom_level
            start_time = max(0, self.current_time - visible_duration / 2)

            # è®¡ç®—å½“å‰æ—¶é—´åœ¨å±å¹•ä¸Šçš„ä½ç½®
            if start_time <= self.current_time <= start_time + visible_duration:
                x = int((self.current_time - start_time) / visible_duration * width)

                # ç»˜åˆ¶æ—¶é—´çº¿
                painter.setPen(QPen(QColor("#f44336"), 2))
                painter.drawLine(x, 0, x, height)

        except Exception as e:
            logger.error(f"ç»˜åˆ¶å½“å‰æ—¶é—´æŒ‡ç¤ºå™¨å¤±è´¥: {e}")

    def mousePressEvent(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if event.button() == Qt.MouseButton.LeftButton:
            time = self.pixel_to_time(event.position().x())
            segment = self.find_segment_at_time(time)

            if segment:
                self.selected_segment_id = segment.segment_id
                self.segment_selected.emit(segment.segment_id)

                # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»åœ¨è°ƒæ•´æ‰‹æŸ„ä¸Š
                self.drag_mode = self.get_drag_mode(event.position().x(), segment)
                if self.drag_mode:
                    self.dragging_segment = segment
                    self.drag_start_pos = event.position()

                self.update()
            else:
                # ç‚¹å‡»ç©ºç™½åŒºåŸŸï¼Œå–æ¶ˆé€‰æ‹©
                self.selected_segment_id = None
                self.update()

    def mouseMoveEvent(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if self.dragging_segment and self.drag_mode:
            # è®¡ç®—æ—¶é—´åç§»
            time_offset = self.pixel_to_time(event.position().x()) - self.pixel_to_time(self.drag_start_pos.x())

            # æ ¹æ®æ‹–æ‹½æ¨¡å¼è°ƒæ•´æ—¶é—´æ®µ
            if self.drag_mode == 'move':
                # ç§»åŠ¨æ•´ä¸ªæ—¶é—´æ®µ
                new_start = max(0, self.dragging_segment.start_time + time_offset)
                new_end = new_start + self.dragging_segment.duration

                if new_end <= self.duration:
                    self.dragging_segment.start_time = new_start
                    self.dragging_segment.end_time = new_end

            elif self.drag_mode == 'resize_start':
                # è°ƒæ•´å¼€å§‹æ—¶é—´
                new_start = max(0, self.dragging_segment.start_time + time_offset)
                if new_start < self.dragging_segment.end_time - 0.1:  # æœ€å°æ—¶é•¿0.1ç§’
                    self.dragging_segment.start_time = new_start

            elif self.drag_mode == 'resize_end':
                # è°ƒæ•´ç»“æŸæ—¶é—´
                new_end = min(self.duration, self.dragging_segment.end_time + time_offset)
                if new_end > self.dragging_segment.start_time + 0.1:  # æœ€å°æ—¶é•¿0.1ç§’
                    self.dragging_segment.end_time = new_end

            self.update()

    def mouseReleaseEvent(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        if self.dragging_segment and self.drag_mode:
            # å‘é€ä¿®æ”¹ä¿¡å·
            changes = {
                "start_time": self.dragging_segment.start_time,
                "end_time": self.dragging_segment.end_time
            }
            self.segment_modified.emit(self.dragging_segment.segment_id, changes)

            # é‡ç½®æ‹–æ‹½çŠ¶æ€
            self.dragging_segment = None
            self.drag_mode = None
            self.drag_start_pos = None

    def find_segment_at_time(self, time: float) -> Optional[PreciseTimeSegment]:
        """æŸ¥æ‰¾æŒ‡å®šæ—¶é—´çš„æ—¶é—´æ®µ"""
        for segment in self.segments:
            if segment.start_time <= time <= segment.end_time:
                return segment
        return None

    def get_drag_mode(self, x: float, segment: PreciseTimeSegment) -> Optional[str]:
        """è·å–æ‹–æ‹½æ¨¡å¼"""
        # è®¡ç®—æ—¶é—´æ®µåœ¨å±å¹•ä¸Šçš„ä½ç½®
        visible_duration = self.duration / self.zoom_level
        start_time = max(0, self.current_time - visible_duration / 2)

        seg_start_x = int((segment.start_time - start_time) / visible_duration * self.width())
        seg_end_x = int((segment.end_time - start_time) / visible_duration * self.width())

        # æ£€æŸ¥æ˜¯å¦åœ¨è°ƒæ•´æ‰‹æŸ„èŒƒå›´å†…
        if abs(x - seg_start_x) <= 5:
            return 'resize_start'
        elif abs(x - seg_end_x) <= 5:
            return 'resize_end'
        elif seg_start_x <= x <= seg_end_x:
            return 'move'

        return None

    def pixel_to_time(self, x: float) -> float:
        """åƒç´ åæ ‡è½¬æ¢ä¸ºæ—¶é—´"""
        if self.duration == 0:
            return 0.0

        visible_duration = self.duration / self.zoom_level
        start_time = max(0, self.current_time - visible_duration / 2)

        time = start_time + (x / self.width()) * visible_duration

        # æ ¹æ®ç²¾åº¦è°ƒæ•´
        precision_value = self.time_precision.value
        return round(time / precision_value) * precision_value
